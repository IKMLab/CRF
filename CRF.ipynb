{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_file = \"../data/D_template\"\n",
    "train_data = \"../data/D_training.data\"\n",
    "model_path = \"../data/D_training.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CRF Done.\n"
     ]
    }
   ],
   "source": [
    "# os.system(\"././CRF++-0.58/crf_learn -f 1 -c 1.0 -p 1 \"+ template_file +\" \"+ train_data +\" \"+ model_path)\n",
    "# print('Train CRF Done.')\n",
    "try :\n",
    "    result = subprocess.check_output(\"../CRF++-0.58/crf_learn -f 1 -c 1.0 -p 1 \"+ template_file +\" \"+ train_data +\" \"+ model_path, shell=True, stderr=subprocess.STDOUT)\n",
    "except subprocess.CalledProcessError as e :\n",
    "    raise RuntimeError(\"command '{}' return with error (code {}):{}\".format(e.cmd,e.returncode, e.output))\n",
    "print('Train CRF Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"../data/D_testing.data\"\n",
    "pd_result = \"../data/predict_res\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test CRF Done.\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    result = subprocess.check_output(\"../CRF++-0.58/crf_test -m \"+ model_path +\" \"+ test_data+\" > \"+ pd_result, shell=True, stderr=subprocess.STDOUT)\n",
    "except subprocess.CalledProcessError as e :\n",
    "    raise RuntimeError(\"command '{}' return with error (code {}):{}\".format(e.cmd,e.returncode, e.output))\n",
    "print('Test CRF Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn predict result into PubTator format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = '../corpus/CDR_TestSet.PubTator.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCorpus(path):\n",
    "\tset_dict = dict()\n",
    "\tpmID_list = list()\n",
    "\twith open(path,'r') as file:\n",
    "\t\tfor row in file:\n",
    "\t\t\trow = row.strip(\"\\n\\r\")\n",
    "\t\t\tif \"|t|\" in row:\n",
    "\t\t\t\tpmID = row.split(\"|t|\")[0]\n",
    "\t\t\t\tpmID_list.append(pmID)\n",
    "\t\t\t\tcontent = row.split(\"|t|\")[1]\n",
    "\t\t\t\t# store the title\n",
    "\t\t\t\tset_dict[pmID] = [row]\n",
    "\t\t\telif \"|a|\" in row:\n",
    "\t\t\t\tpmID = row.split(\"|a|\")[0]\n",
    "\t\t\t\tcontent += ' ' + row.split(\"|a|\")[1]\n",
    "\t\t\t\t# store the abtract\n",
    "\t\t\t\tset_dict[pmID].append(row)\n",
    "\t\t\t\t# store the whole article without the pmID, '|t|' & '|a|'\n",
    "\t\t\t\tset_dict[pmID].append(content)\n",
    "\n",
    "\treturn set_dict, pmID_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dict, gt_PMID_list = readCorpus(gt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(pd_path, set_dict, pmID_list):\n",
    "\n",
    "\t# load the result file\n",
    "\tall_disease_list = load_resultFile(pd_path)\n",
    "\tprint('load file done')\n",
    "\n",
    "\t# run through every article\n",
    "\tfor idx in range(len(pmID_list)):\n",
    "\t\tpmID = pmID_list[idx]\n",
    "\t\t\n",
    "\t\tcontent = set_dict[pmID][2]\n",
    "\t\tprd_mentions_list = all_disease_list[idx]\n",
    "\t\tNER_list = list()\n",
    "\n",
    "\t\ttmp_position = 0\n",
    "\n",
    "\t\tfor prd_part_of_mention in prd_mentions_list:\n",
    "\n",
    "\t\t\tmention = ''\n",
    "\t\t\tfor part_idx in range(len(prd_part_of_mention)):\n",
    "\t\t\t\tif content.find(mention + prd_part_of_mention[part_idx], tmp_position) != -1:\n",
    "\t\t\t\t\tmention = mention + prd_part_of_mention[part_idx]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tstart_offset = content.find(mention, tmp_position)\n",
    "\n",
    "\t\t\t\telif content.find(mention + ' ' + prd_part_of_mention[part_idx] , tmp_position) != -1:\n",
    "\t\t\t\t\tmention = mention + ' ' + prd_part_of_mention[part_idx]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tstart_offset = content.find(mention, tmp_position)\n",
    "\n",
    "\t\t\tNER = pmID + '\\t' + str(start_offset) + '\\t' + str(start_offset+len(mention)) + '\\t' + mention + '\\t' + 'Disease' + '\\n'\n",
    "\t\t\tNER_list.append(NER)\n",
    "\t\t\ttmp_position = content.find(mention, tmp_position) + len(mention)\n",
    "\n",
    "\t\tset_dict[pmID].append(NER_list)\n",
    "\treturn set_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resultFile(path):\n",
    "\t# store all the mentions of all the articles\n",
    "\tall_disease_list = list()\n",
    "\t# store all the mentions of the article\n",
    "\tmentions_list = list()\n",
    "\t# store every token in a mention\n",
    "\tpart_of_mention = list()\n",
    "\n",
    "\twith open(path,'r') as predict_file:\n",
    "\t\tfor row in predict_file:\n",
    "\t\t\trow = row.rstrip('\\n\\r')\n",
    "\n",
    "\t\t\t# if the row is empty means this article is ended\n",
    "\t\t\tif len(row) == 0:\n",
    "\t\t\t\t# if the mention appears at the end of the article, and store it\n",
    "\t\t\t\tif len(part_of_mention) != 0:\n",
    "\t\t\t\t\tmentions_list.append(part_of_mention)\n",
    "\t\t\t\t# store all the mention that appear in this article into mention_list, and clear the lists\n",
    "\t\t\t\tall_disease_list.append(mentions_list)\n",
    "\t\t\t\tpart_of_mention = list()\n",
    "\t\t\t\tmentions_list = list()\n",
    "\t\t\telse:\n",
    "\t\t\t\t# get the token and tag\n",
    "\t\t\t\ttoken = row.split()[0]\n",
    "\t\t\t\ttag = row.split()[-1]\n",
    "\n",
    "\t\t\t\tif tag.split('-')[0] == 'B':\n",
    "\t\t\t\t\t# if the tag is 'B' may be a beginning of a mention or a independent mention that only includes one token\n",
    "\t\t\t\t\t# 'B' with 'B', store the previous mention and clear the list\n",
    "\t\t\t\t\tif len(part_of_mention) != 0:\n",
    "\t\t\t\t\t\tmentions_list.append(part_of_mention)\n",
    "\t\t\t\t\t\tpart_of_mention = list()\n",
    "\t\t\t\t\tpart_of_mention = [token]\n",
    "\t\t\t\telif tag.split('-')[0] == 'I':\n",
    "\t\t\t\t\tpart_of_mention.append(token)\n",
    "\t\t\t\telif tag.split('-')[0] == 'E':\n",
    "\t\t\t\t\tpart_of_mention.append(token)\n",
    "\t\t\t\t\t# 'E' is the last label in a mention, store the mention and clear the list\n",
    "\t\t\t\t\tmentions_list.append(part_of_mention)\n",
    "\t\t\t\t\tpart_of_mention = list()\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tif len(part_of_mention) != 0:\n",
    "\t\t\t\t\t\tmentions_list.append(part_of_mention)\n",
    "\t\t\t\t\t\tpart_of_mention = list()\n",
    "\t\t\n",
    "\treturn all_disease_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file done\n"
     ]
    }
   ],
   "source": [
    "pd_dict = NER(pd_result, gt_dict, gt_PMID_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_NER_path = '../data/NER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_NERFile(set_dict, pmID_list, R_path):\n",
    "\tNER_file = open(R_path, 'w')\n",
    "\n",
    "\tfor pmID in pmID_list:\n",
    "\t\ttitle = set_dict[pmID][0] + '\\n'\n",
    "\t\tabstract = set_dict[pmID][1] + '\\n'\n",
    "\t\tNER_list = set_dict[pmID][3]\n",
    "\n",
    "\t\tNER_str = ''\n",
    "\t\tfor NER in NER_list:\n",
    "\t\t\tNER_str += NER\n",
    "\n",
    "\t\tNER_file.write(title+abstract+NER_str+'\\n')\n",
    "\n",
    "\tNER_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Done.\n"
     ]
    }
   ],
   "source": [
    "product_NERFile(pd_dict, gt_PMID_list, pd_NER_path)\n",
    "print('NER Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_result_path = '../evaluation/eva_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'TP: 3040\\nFP: 786\\nFN: 1384\\nPrecision: 0.7945635128071092\\nRecall: 0.6871609403254972\\nF-score: 0.7369696969696969\\n'\n",
      "Evaluate Done.\n"
     ]
    }
   ],
   "source": [
    "try :\n",
    "    result = subprocess.check_output(\"sh ../evaluation/eval_mention.sh PubTator \" + gt_path + \" \" + pd_NER_path + \" \" + eva_result_path, shell=True, stderr=subprocess.STDOUT)\n",
    "except subprocess.CalledProcessError as e :\n",
    "    raise RuntimeError(\"command '{}' return with error (code {}):{}\".format(e.cmd,e.returncode, e.output))\n",
    "print(result)\n",
    "print('Evaluate Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
