{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature - Length\n",
    "加入Token的長度(length)作為CRF++訓練模型的Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "加入每個Token的長度作為Feature加入CRF的Train Data中，以下為完成後的資料格式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀檔路徑、存檔路徑\n",
    "traindemofile = \"../Data/Train_demo.data\"\n",
    "testdemofile = \"../Data/Test_demo.data\"\n",
    "\n",
    "fopen = open(traindemofile, 'r', encoding='utf-8')\n",
    "traindemo = fopen.readlines()\n",
    "fopen = open(testdemofile, 'r', encoding='utf-8')\n",
    "testdemo = fopen.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data\n",
    "\n",
    "存於檔案中之格式如下:\n",
    "\n",
    "Sequential 10 O\n",
    "\n",
    "involvement 11 O\n",
    "\n",
    "of 2 O\n",
    "\n",
    "...\n",
    "\n",
    "initiation 10 O\n",
    "\n",
    ". 1 O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sequential\\t10\\tO\\n' 'involvement\\t11\\tO\\n' 'of\\t2\\tO\\n' ...\n",
      " 'initiation\\t10\\tO\\n' '.\\t1\\tO\\n' '\\n']\n"
     ]
    }
   ],
   "source": [
    "#Train Data\n",
    "print(np.array(traindemo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data\n",
    "存於檔案中之格式如下:\n",
    "\n",
    "A 1\n",
    "\n",
    "photo 5\n",
    "\n",
    "-responsive 11\n",
    "\n",
    "...\n",
    "\n",
    "infection 9\n",
    "\n",
    ". 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A\\t1\\n' 'photo\\t5\\n' '-responsive\\t11\\n' ... 'infection\\t9\\n' '.\\t1\\n'\n",
      " '\\n']\n"
     ]
    }
   ],
   "source": [
    "#Test Data\n",
    "print(np.array(testdemo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise\n",
    "完成以下程式碼，建立以長度為Feature的Train Data及Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀檔路徑、存檔路徑\n",
    "traininputfile = \"../Data/Train.data\"\n",
    "trainoutputfile = \"../Data/Train_len.data\"\n",
    "testinputfile = \"../Data/Test.data\"\n",
    "testoutputfile = \"../Data/Test_len.data\"\n",
    "\n",
    "if os.path.isfile(trainoutputfile):\n",
    "    os.remove(trainoutputfile)\n",
    "if os.path.isfile(testoutputfile):\n",
    "    os.remove(testoutputfile)\n",
    "\n",
    "fopen = open(traininputfile, 'r', encoding='utf-8')\n",
    "train = fopen.readlines()\n",
    "fopen = open(testinputfile, 'r', encoding='utf-8')\n",
    "test = fopen.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 127779\n"
     ]
    }
   ],
   "source": [
    "#Train data的內容\n",
    "print(train)\n",
    "\n",
    "#TODO:將Train Data加上Token長度的 Feature\n",
    "traindata = \"\"\n",
    "token = 0\n",
    "for text in train:\n",
    "    #reference: len()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #計算Token數量\n",
    "    token = token + 1\n",
    "print(\"Token: \" + str(token))\n",
    "\n",
    "#完成traindata之後將下面的註解符號(#)刪除，進行存檔\n",
    "#fopen = open(trainoutputfile, 'w', encoding='utf-8')\n",
    "#fopen.write(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 32269\n"
     ]
    }
   ],
   "source": [
    "#Test data的內容\n",
    "print(test)\n",
    "\n",
    "#TODO:將Test Data加上Token長度的 Feature\n",
    "testdata = \"\"\n",
    "token = 0\n",
    "for text in test:\n",
    "    #reference: len()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #計算Token數量\n",
    "    token = token + 1\n",
    "print(\"Token: \" + str(token))\n",
    "    \n",
    "#完成testdata之後將下面的註解符號(#)刪除，進行存檔\n",
    "#fopen = open(testoutputfile, 'w', encoding='utf-8')\n",
    "#fopen.write(testdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
